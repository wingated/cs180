{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPir_6bCCFnZ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wingated/cs180/blob/main/data_science_labs/data_science_lab_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b>After clicking the \"Open in Colab\" link, copy the notebook to your own Google Drive before getting started, or it will not save your work</b></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_slaQdUGCB0t"
      },
      "source": [
        "# BYU CS 180 Lab 9: Gen AI for Data Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct7fnkcnCL8O"
      },
      "source": [
        "## Introduction:\n",
        "In this lab, you will practice using generative AI as part of a data science workflow.\n",
        "\n",
        "For this project, you will use a language model to analyze unstructured text and visualize the results. The text comes from transcripts of news coverage during April 2020, during the COVID-19 outbreak. There are 1,000 total transcripts.  Each transcript is of an interview. (This is a subset of the MediaSum dataset, https://github.com/zcgzcgzcg1/MediaSum)\n",
        "\n",
        "Each interview consists of the text of the transcript, plus metadata about the transcript (such as the date, the program it was broadcast on, etc.)\n",
        "\n",
        "For our purposes, we are mostly interested in the \"utt\" field of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 1: downloading and loading\n",
        "\n",
        "### Step 1: download and load the data\n",
        "\n",
        "Begin by downloading the data from the class website:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wget https://wingated.github.io/cs180/covid1k.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and loading it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "data = json.load( open(\"covid1k.json\", \"r\") )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 2: extraction\n",
        "\n",
        "For each transcript, your task is to figure out who the interviewer is, who the guest is, and whether or not the guest is a medical doctor.\n",
        "\n",
        "This task is easy for humans, but is hard for traditional NLP methods such as keyword analysis, parsing, part-of-speech tagging, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do this, we will use generative AI - specifically, a large language model. Here is an example of using the OpenAI ChatCompletion API to take a prompt, generate and return a completion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = \"XXX PUT YOUR API KEY HERE XXX\"\n",
        "\n",
        "def do_query( messages, max_tokens=512, temperature=1.0, model=\"gpt-4o-mini\" ):\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        messages=messages,\n",
        "        model=model,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        )\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "prompt = \"When asked whether Coke or Pepsi is better, I respond that\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": prompt },\n",
        "]\n",
        "\n",
        "response = do_query( messages )\n",
        "\n",
        "print( response )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You must do the following:\n",
        "\n",
        "* Create a prompt template\n",
        "* For each transcript\n",
        "  * Create a prompt from the template\n",
        "  * Run the prompt through the language model\n",
        "* Store the results in an appropriate datastructure\n",
        "  * You may want to store additional meta-data about the interview, to support visualizations later on!\n",
        "\n",
        "Then, you must:\n",
        "* For each result:\n",
        "  * Parse the result and determine the interviewer, the guest, and whether or not they are a doctor.\n",
        "* Create a dataframe with the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When all is said and done, you should have a data frame that looks something like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "       interviewer              guest  is_doctor                      program        date\n",
        "0         Anderson   Dr. Sanjay Gupta       True  ANDERSON COOPER 360 DEGREES  2020-04-01\n",
        "1         Anderson  Dr. Craig Spencer       True  ANDERSON COOPER 360 DEGREES  2020-04-01\n",
        "2         Anderson   Gretchen Whitmer      False  ANDERSON COOPER 360 DEGREES  2020-04-01\n",
        "3        Carl Azuz   Dr. Sanjay Gupta       True                       CNN 10  2020-04-01\n",
        "4       John Vause      Dr. Raj Kalsi       True                 CNN NEWSROOM  2020-04-01\n",
        "5             John       Steven Jiang      False                 CNN NEWSROOM  2020-04-01\n",
        "6       Jim Acosta  Dr. Anthony Fauci       True                 CNN NEWSROOM  2020-04-01\n",
        "7             John         Vedika Sud      False                 CNN NEWSROOM  2020-04-01\n",
        "8       John Vause       Amanda Davis      False                 CNN NEWSROOM  2020-04-01\n",
        "9  Rosemary Church   Anthony Costello       True                 CNN NEWSROOM  2020-04-01\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Hints:**\n",
        "\n",
        "You may need to try multiple prompt templates to get one that works. Experiment on a subset of the data (maybe only 10 interviews) until you get something working.\n",
        "\n",
        "Make the language model do the work! You can ask it to output its answers to your questions in a structured format that's easy to parse.\n",
        "\n",
        "Major hint: I asked the language model to output its results in JSON format, and it worked almost flawlessly.  You may need to do some post-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 3: visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With our newly processed data in hand, craft three interesting visualizations.  These can be anything you want -- maybe the percentage of times a doctor was interviewed on CNN vs. NPR? Maybe a per-host breakdown of guests? Maybe a trend over time? etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
