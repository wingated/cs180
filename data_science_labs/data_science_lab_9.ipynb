{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPir_6bCCFnZ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/porterjenkins/CS180/blob/main/data_science_labs/data_science_lab_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b>After clicking the \"Open in Colab\" link, copy the notebook to your own Google Drive before getting started, or it will not save your work</b></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_slaQdUGCB0t"
      },
      "source": [
        "# BYU CS 180 Lab 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct7fnkcnCL8O"
      },
      "source": [
        "## Introduction:\n",
        "In this lab, you will practice using generative AI as part of a data science workflow. This project mirrors a real research project, with a similar (but simplified) pipeline that involves various stages of processing and visualization.\n",
        "\n",
        "For this project, you will use a language model to analyze unstructured text and visualize the results. The text comes from interviews with parents of autistic daughters. The purpose of the interviews is to identify early warning signs of autism.\n",
        "\n",
        "Unfortunately, each interview is wide ranging, and (like real conversations) includes a lot of irrelevant text. Our goal is analyze the text, focus on concrete observations about the autistic girls, and build a visualization that captures patterns in what parents said.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 1: loading and cleaning\n",
        "\n",
        "### Step 1: download the data\n",
        "\n",
        "Begin by downloading the data from the class website. There are 18 transcripts.\n",
        "\n",
        "### Step 2: load the data\n",
        "\n",
        "Each datafile is a JSON file. Inside each is a single dictionary, with a \"Paragraphs\" key that maps to a list of paragraphs of text. Create a new DataFrame object with a single row for each paragraph. You should also have a column that represents the filename that each paragraph came from, and a column that represents the column number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 2: extraction\n",
        "\n",
        "Each paragraph is cluttered with extraneous text, and may or may not contain any concrete observations about their child's development. Our first task is to analyze each paragraph, and **extract only concrete observations about their children.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do this, we will use generative AI - specifically, a large language model. Here is an example of using the OpenAI ChatCompletion API to take a prompt, generate and return a completion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = \"XXX PUT YOUR API KEY HERE XXX\"\n",
        "\n",
        "def do_query( messages, max_tokens=512, temperature=1.0, model=\"gpt-4o\" ):\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        messages=messages,\n",
        "        model=model,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        )\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "prompt = \"When asked whether Coke or Pepsi is better, I respond that \"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": prompt },\n",
        "]\n",
        "\n",
        "response = do_query( messages )\n",
        "\n",
        "print( response )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You must do the following:\n",
        "\n",
        "* Create a prompt template\n",
        "* For each paragraph\n",
        "  * Create a prompt from the template\n",
        "  * Run the prompt through the language model\n",
        "* Store the results in an appropriate datastructure\n",
        "\n",
        "Then, you must:\n",
        "* For each result:\n",
        "  * Parse the result and split it into individual concrete observations\n",
        "* Create a dataframe with the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When all is said and done, you should have a data file that looks something like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "In [1]: df\n",
        "Out[1]: \n",
        "                   filename  paragraph_number                               concrete_observation\n",
        "0     interview222-282.json                 2      had the cord wrapped around her neck at birth\n",
        "1     interview222-282.json                 2                        was slower learning to talk\n",
        "2     interview222-282.json                 2                        was slower learning to walk\n",
        "3     interview222-282.json                 3                             didn't crawl as a baby\n",
        "4     interview222-282.json                 3                      walked without crawling first\n",
        "...                     ...               ...                                                ...\n",
        "2530   interview222-91.json                21  People perceived her as older due to her wise ...\n",
        "2531   interview222-91.json                21                 always wanted to do what was right\n",
        "2532   interview222-91.json                22                    has been an easy child to raise\n",
        "2533   interview222-91.json                22                   is harder on herself than others\n",
        "2534   interview222-91.json                23                    wants to continue her education\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 3: classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With our concrete observations in hand, the goal is now to see what patterns in our data exist. To do this, we will classify each observation according to the general topic it relates to. For example, many observations are about \"social struggles\", or \"early reading\".  For the purposes of this lab, we will classify observations into the following categories:\n",
        "\n",
        "* Reading excellence\n",
        "* Reading challenges\n",
        "* Social struggles\n",
        "* Sensory sentivities\n",
        "* Developmental delays\n",
        "* Other / miscellaneous\n",
        "\n",
        "The process for this section is similar to the previous one.  You must:\n",
        "\n",
        "* For each concrete observation\n",
        "  * Generate a prompt that asks the language model to classify the observation into one of the 6 categories\n",
        "* Store the results as a new column\n",
        "\n",
        "This will result in an additional column in your dataframe. Make sure to save your work!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 4: visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, what were the results? Build a visualization to clearly communicate the results of your analysis.  This part is up to you -- pretend you're a real data scientist, working for a real psychologist.  What would s/he want to know about the data? What patterns are evident? What can we conclude from the data? What *can't* we conclude?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
